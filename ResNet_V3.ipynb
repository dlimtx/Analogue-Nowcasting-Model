{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "046606f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "\n",
    "# Load the data for both years\n",
    "#data_2020 = nc.Dataset('/Users/heyj/Desktop/sql project/2020data.nc')\n",
    "#data_2021 = nc.Dataset('/Users/heyj/Desktop/sql project/2020data.nc')\n",
    "data_2020 = nc.Dataset('2020data00UTC.nc') #(choose a specific timestamp: 00UTC for each day)\n",
    "data_2021 = nc.Dataset('2021data00UTC.nc')\n",
    "\n",
    "# Combine data from both years\n",
    "z_combined = np.concatenate((data_2020['z'][:], data_2021['z'][:]), axis=0)\n",
    "u_combined = np.concatenate((data_2020['u'][:], data_2021['u'][:]), axis=0)\n",
    "v_combined = np.concatenate((data_2020['v'][:], data_2021['v'][:]), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "506fe0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class:  MaskedArray\n",
      "shape:  (365, 3, 81, 101)\n",
      "strides:  (196344, 65448, 808, 8)\n",
      "itemsize:  8\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  False\n",
      "data pointer: 0x7f1800887010\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: float64\n"
     ]
    }
   ],
   "source": [
    "# check the dimension\n",
    "np.info(data_2020['z'][:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dfb4504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class:  MaskedArray\n",
      "shape:  (731, 3, 81, 101)\n",
      "strides:  (196344, 65448, 808, 8)\n",
      "itemsize:  8\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  False\n",
      "data pointer: 0x7f16c8ea7010\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: float64\n"
     ]
    }
   ],
   "source": [
    "# check the dimension\n",
    "np.info(z_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "729fa736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions:\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'longitude', size = 101\n",
      "\n",
      "\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'latitude', size = 81\n",
      "\n",
      "\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'level', size = 3\n",
      "\n",
      "\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'time', size = 365\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions:\")\n",
    "for dim in data_2020.dimensions.values():\n",
    "    print(dim)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "908a837e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class:  ndarray\n",
      "shape:  (731, 4, 82, 102, 3)\n",
      "strides:  (802944, 200736, 2448, 24, 8)\n",
      "itemsize:  8\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  False\n",
      "data pointer: 0x7f167615e010\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: float64\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "z_normalized = scaler.fit_transform(z_combined.reshape(-1, 1)).reshape(z_combined.shape)\n",
    "u_normalized = scaler.fit_transform(u_combined.reshape(-1, 1)).reshape(u_combined.shape)\n",
    "v_normalized = scaler.fit_transform(v_combined.reshape(-1, 1)).reshape(v_combined.shape)\n",
    "\n",
    "# Combine the parameters to form a single dataset\n",
    "data_combined = np.stack((z_normalized, u_normalized, v_normalized), axis=-1)\n",
    "\n",
    "# Pad the data to get even dimensions\n",
    "padded_data = np.pad(data_combined, ((0, 0), (0, 1), (0, 1), (0, 1), (0, 0)), mode='constant')\n",
    "np.info(padded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae225987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "z_normalized = scaler.fit_transform(z_combined.reshape(-1, 1)).reshape(z_combined.shape)\n",
    "u_normalized = scaler.fit_transform(u_combined.reshape(-1, 1)).reshape(u_combined.shape)\n",
    "v_normalized = scaler.fit_transform(v_combined.reshape(-1, 1)).reshape(v_combined.shape)\n",
    "\n",
    "# Combine the parameters to form a single dataset\n",
    "data_combined = np.stack((z_normalized, u_normalized, v_normalized), axis=-1)\n",
    "\n",
    "# Pad the data to get even dimensions\n",
    "padded_data = np.pad(data_combined, ((0, 0), (0, 1), (0, 1), (0, 1), (0, 0)), mode='constant')\n",
    "\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val = train_test_split(padded_data, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9c134c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (511, 4, 82, 102, 3)\n",
      "Validation data shape (220, 4, 82, 102, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shape\", X_train.shape)\n",
    "print(\"Validation data shape\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed38a958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 4, 82, 102,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, 4, 82, 102, 3 2624        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 4, 82, 102, 3 128         conv3d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4, 82, 102, 3 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 4, 82, 102, 3 27680       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 82, 102, 3 128         conv3d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 4, 82, 102, 3 128         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4, 82, 102, 3 0           batch_normalization_11[0][0]     \n",
      "                                                                 conv3d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 82, 102, 3 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_19 (Conv3D)              (None, 4, 82, 102, 6 55360       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 82, 102, 6 256         conv3d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 82, 102, 6 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_20 (Conv3D)              (None, 4, 82, 102, 6 110656      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 4, 82, 102, 6 256         conv3d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_21 (Conv3D)              (None, 4, 82, 102, 6 2112        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 82, 102, 6 0           batch_normalization_13[0][0]     \n",
      "                                                                 conv3d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 4, 82, 102, 6 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_22 (Conv3D)              (None, 2, 41, 51, 12 221312      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 2, 41, 51, 12 512         conv3d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 2, 41, 51, 12 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_23 (Conv3D)              (None, 2, 41, 51, 12 442496      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 2, 41, 51, 12 512         conv3d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_24 (Conv3D)              (None, 2, 41, 51, 12 8320        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2, 41, 51, 12 0           batch_normalization_15[0][0]     \n",
      "                                                                 conv3d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 2, 41, 51, 12 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3D)  (None, 4, 82, 102, 1 0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_25 (Conv3D)              (None, 4, 82, 102, 6 221248      up_sampling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4, 82, 102, 6 256         conv3d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4, 82, 102, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_26 (Conv3D)              (None, 4, 82, 102, 6 110656      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 82, 102, 6 256         conv3d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_27 (Conv3D)              (None, 4, 82, 102, 6 8256        up_sampling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4, 82, 102, 6 0           batch_normalization_17[0][0]     \n",
      "                                                                 conv3d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 82, 102, 6 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_3 (UpSampling3D)  (None, 4, 82, 102, 6 0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_28 (Conv3D)              (None, 4, 82, 102, 3 55328       up_sampling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 4, 82, 102, 3 128         conv3d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 82, 102, 3 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_29 (Conv3D)              (None, 4, 82, 102, 3 27680       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 4, 82, 102, 3 128         conv3d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_30 (Conv3D)              (None, 4, 82, 102, 3 2080        up_sampling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 4, 82, 102, 3 0           batch_normalization_19[0][0]     \n",
      "                                                                 conv3d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 4, 82, 102, 3 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_31 (Conv3D)              (None, 4, 82, 102, 3 2595        activation_19[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,301,091\n",
      "Trainable params: 1,299,811\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv3D, UpSampling3D, Add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define ResNet block\n",
    "def resnet_block(input_tensor, filters, kernel_size=(3, 3, 3), strides=(1, 1, 1)):\n",
    "    x = Conv3D(filters, kernel_size, strides=strides, padding='same')(input_tensor)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    x = Conv3D(filters, kernel_size, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Adjust the shortcut connection\n",
    "    if strides != (1, 1, 1) or input_tensor.shape[-1] != filters:\n",
    "        shortcut = Conv3D(filters, (1, 1, 1), strides=strides, padding='same')(input_tensor)\n",
    "    else:\n",
    "        shortcut = input_tensor\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "input_shape_padded = (4, 82, 102, 3)\n",
    "inputs = Input(shape=input_shape_padded)\n",
    "\n",
    "# Encoder\n",
    "x = resnet_block(inputs, 32)\n",
    "x = resnet_block(x, 64)\n",
    "encoded = resnet_block(x, 128, strides=(2, 2, 2))\n",
    "\n",
    "# Decoder\n",
    "x = UpSampling3D((2, 2, 2))(encoded)\n",
    "x = resnet_block(x, 64)\n",
    "x = UpSampling3D((1, 1, 1))(x)\n",
    "x = resnet_block(x, 32)\n",
    "decoded = Conv3D(3, (3, 3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder = Model(inputs, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Print the model summary\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5aa2d3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "899f646e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 28s 1s/step - loss: 0.0185 - val_loss: 0.0124\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 16s 1s/step - loss: 0.0011 - val_loss: 0.0132\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 16s 1s/step - loss: 5.1710e-04 - val_loss: 0.0110\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 16s 1s/step - loss: 3.6860e-04 - val_loss: 0.0081\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 17s 1s/step - loss: 2.9840e-04 - val_loss: 0.0061\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 18s 1s/step - loss: 2.5190e-04 - val_loss: 0.0057\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 19s 1s/step - loss: 2.1882e-04 - val_loss: 0.0050\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 19s 1s/step - loss: 2.8246e-04 - val_loss: 0.0041\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 19s 1s/step - loss: 2.4635e-04 - val_loss: 0.0038\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 20s 1s/step - loss: 2.0945e-04 - val_loss: 0.0042\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 20s 1s/step - loss: 2.7053e-04 - val_loss: 0.0045\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 20s 1s/step - loss: 3.4293e-04 - val_loss: 0.0038\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 20s 1s/step - loss: 2.2323e-04 - val_loss: 0.0043\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 20s 1s/step - loss: 1.5829e-04 - val_loss: 0.0038\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 21s 1s/step - loss: 1.9069e-04 - val_loss: 0.0041\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 21s 1s/step - loss: 2.0367e-04 - val_loss: 0.0042\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 21s 1s/step - loss: 2.8455e-04 - val_loss: 0.0022\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 22s 1s/step - loss: 2.4585e-04 - val_loss: 0.0029\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 23s 1s/step - loss: 1.7405e-04 - val_loss: 0.0030\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 23s 1s/step - loss: 1.7130e-04 - val_loss: 0.0030\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 23s 1s/step - loss: 1.1391e-04 - val_loss: 0.0035\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 23s 1s/step - loss: 2.1314e-04 - val_loss: 0.0029\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 24s 1s/step - loss: 1.3021e-04 - val_loss: 0.0023\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 24s 1s/step - loss: 1.1922e-04 - val_loss: 0.0026\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 24s 1s/step - loss: 1.0314e-04 - val_loss: 0.0023\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 24s 1s/step - loss: 1.3317e-04 - val_loss: 0.0019\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 23s 1s/step - loss: 1.5411e-04 - val_loss: 0.0015\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 24s 2s/step - loss: 8.2469e-05 - val_loss: 0.0015\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 24s 1s/step - loss: 1.1573e-04 - val_loss: 0.0020\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 23s 1s/step - loss: 9.5026e-05 - val_loss: 0.0015\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 24s 2s/step - loss: 1.5104e-04 - val_loss: 0.0014\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 23s 1s/step - loss: 1.3523e-04 - val_loss: 6.9286e-04\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 24s 2s/step - loss: 1.6231e-04 - val_loss: 6.7940e-04\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 24s 1s/step - loss: 1.7898e-04 - val_loss: 4.7221e-04\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 24s 2s/step - loss: 1.7477e-04 - val_loss: 3.4471e-04\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 24s 2s/step - loss: 1.2181e-04 - val_loss: 4.0655e-04\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 24s 2s/step - loss: 1.4371e-04 - val_loss: 7.1925e-04\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 24s 2s/step - loss: 1.1426e-04 - val_loss: 2.5103e-04\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 25s 2s/step - loss: 8.8813e-05 - val_loss: 2.0928e-04\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 24s 2s/step - loss: 9.9977e-05 - val_loss: 5.9745e-04\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 24s 2s/step - loss: 1.0249e-04 - val_loss: 4.0680e-04\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 24s 2s/step - loss: 8.2303e-05 - val_loss: 1.0856e-04\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 24s 2s/step - loss: 1.1324e-04 - val_loss: 2.2348e-04\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 24s 2s/step - loss: 1.0690e-04 - val_loss: 1.7698e-04\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 23s 1s/step - loss: 9.1716e-05 - val_loss: 1.6976e-04\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 25s 2s/step - loss: 9.2097e-05 - val_loss: 1.4506e-04\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 25s 2s/step - loss: 7.3522e-05 - val_loss: 3.0217e-04\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 24s 1s/step - loss: 1.4982e-04 - val_loss: 1.9608e-04\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 25s 2s/step - loss: 1.2769e-04 - val_loss: 1.5020e-04\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 24s 2s/step - loss: 9.5297e-05 - val_loss: 1.0601e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "history = autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, validation_data=(X_val, X_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ecd1192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 4, 82, 102,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, 4, 82, 102, 3 2624        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 4, 82, 102, 3 128         conv3d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4, 82, 102, 3 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 4, 82, 102, 3 27680       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 82, 102, 3 128         conv3d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 4, 82, 102, 3 128         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4, 82, 102, 3 0           batch_normalization_11[0][0]     \n",
      "                                                                 conv3d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 82, 102, 3 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_19 (Conv3D)              (None, 4, 82, 102, 6 55360       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 82, 102, 6 256         conv3d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 82, 102, 6 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_20 (Conv3D)              (None, 4, 82, 102, 6 110656      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 4, 82, 102, 6 256         conv3d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_21 (Conv3D)              (None, 4, 82, 102, 6 2112        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 82, 102, 6 0           batch_normalization_13[0][0]     \n",
      "                                                                 conv3d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 4, 82, 102, 6 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_22 (Conv3D)              (None, 2, 41, 51, 12 221312      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 2, 41, 51, 12 512         conv3d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 2, 41, 51, 12 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_23 (Conv3D)              (None, 2, 41, 51, 12 442496      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 2, 41, 51, 12 512         conv3d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_24 (Conv3D)              (None, 2, 41, 51, 12 8320        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2, 41, 51, 12 0           batch_normalization_15[0][0]     \n",
      "                                                                 conv3d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 2, 41, 51, 12 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3D)  (None, 4, 82, 102, 1 0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_25 (Conv3D)              (None, 4, 82, 102, 6 221248      up_sampling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4, 82, 102, 6 256         conv3d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4, 82, 102, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_26 (Conv3D)              (None, 4, 82, 102, 6 110656      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 82, 102, 6 256         conv3d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_27 (Conv3D)              (None, 4, 82, 102, 6 8256        up_sampling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4, 82, 102, 6 0           batch_normalization_17[0][0]     \n",
      "                                                                 conv3d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 82, 102, 6 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_3 (UpSampling3D)  (None, 4, 82, 102, 6 0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_28 (Conv3D)              (None, 4, 82, 102, 3 55328       up_sampling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 4, 82, 102, 3 128         conv3d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 82, 102, 3 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_29 (Conv3D)              (None, 4, 82, 102, 3 27680       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 4, 82, 102, 3 128         conv3d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_30 (Conv3D)              (None, 4, 82, 102, 3 2080        up_sampling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 4, 82, 102, 3 0           batch_normalization_19[0][0]     \n",
      "                                                                 conv3d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 4, 82, 102, 3 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_31 (Conv3D)              (None, 4, 82, 102, 3 2595        activation_19[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,301,091\n",
      "Trainable params: 1,299,811\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a215ffce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.00010600513860469818\n",
      "Mean Absolute Error: 0.006431017596301612\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconstruction Error:Evaluate how well the autoencoder can reconstruct the input data\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "decoded_val = autoencoder.predict(X_val)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(X_val.flatten(), decoded_val.flatten())\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(X_val.flatten(), decoded_val.flatten())\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b528ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Summary text file\n",
    "original_stdout = sys.stdout  # Save a reference to the original standard output\n",
    "\n",
    "with open('model_summary.txt', 'w') as f:\n",
    "    sys.stdout = f  # Change the standard output to the file we created.\n",
    "    print(autoencoder.summary())\n",
    "    sys.stdout = original_stdout  # Reset the standard output to its original value\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3164a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the history object \n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Convert the history.history dict to a pandas DataFrame\n",
    "hist_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Save to csv\n",
    "hist_csv_file = 'history.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)\n",
    "\n",
    "# Save to pickle\n",
    "with open('history.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc839f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved history \n",
    "\n",
    "loaded_history = pd.read_csv('history.csv')\n",
    "\n",
    "with open('history.pkl', 'rb') as file:\n",
    "    loaded_history = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf1f18af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder model. Find the low dimension layer according to the model summary. 'activation_15' should be the encoder layer\n",
    "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('activation_15').output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32215e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output = autoencoder.get_layer('activation_15').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c5205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianhong/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "autoencoder.save('autoencoder_yjmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1c8fe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "autoencoder.save_weights('autoencoder_yjweights.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a42556b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save whole training database encoded_database\n",
    "encoded_database = encoder.predict(X_train)\n",
    "\n",
    "# Save the encoded data as np and h5py\n",
    "\n",
    "np. save('encoded_database.npy', encoded_database)\n",
    "\n",
    "import h5py\n",
    "\n",
    "with h5py.File('encoded_database', 'w') as h5f:\n",
    "    h5f.create_dataset('dataset_1', data=encoded_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c5b5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 13:03:38.158172: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "autoencoder = load_model('autoencoder_yjmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a002e6b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 81, 101, 3)\n",
      "class:  ndarray\n",
      "shape:  (1, 3, 81, 101, 3)\n",
      "strides:  (589032, 196344, 2424, 24, 8)\n",
      "itemsize:  8\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  False\n",
      "data pointer: 0x559295c33bf0\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: float64\n",
      "class:  ndarray\n",
      "shape:  (1, 4, 82, 102, 3)\n",
      "strides:  (802944, 200736, 2448, 24, 8)\n",
      "itemsize:  8\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  False\n",
      "data pointer: 0x5592961b0a20\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: float64\n"
     ]
    }
   ],
   "source": [
    "# Preprocess and Encode the ##Input Day$$ Data, here use 28th Oct 2023 \n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "Oct_28_2023 = nc.Dataset('Oct_28_00UTC.nc')\n",
    "#Oct_15_2023 = nc.Dataset('/home/jianhong/Desktop/Analogue-Nowcasting-Model (copy)/15_Oct.nc')\n",
    "z_input = Oct_28_2023['z'][:]\n",
    "u_input = Oct_28_2023['u'][:]\n",
    "v_input = Oct_28_2023['v'][:]\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "z_input_normalized = scaler.fit_transform(z_input.reshape(-1, 1)).reshape(z_input.shape)\n",
    "u_input_normalized = scaler.fit_transform(u_input.reshape(-1, 1)).reshape(u_input.shape)\n",
    "v_input_normalized = scaler.fit_transform(v_input.reshape(-1, 1)).reshape(v_input.shape)\n",
    "\n",
    "\n",
    "# Combine the parameters to form a single dataset\n",
    "data_combined = np.stack((z_input_normalized, u_input_normalized , v_input_normalized), axis=-1)\n",
    "print(data_combined.shape)\n",
    "np.info(data_combined)\n",
    "\n",
    "\n",
    "# Pad the data to get even dimensions\n",
    "input_day_padded = np.pad(data_combined, ((0,0),(0, 1), (0, 1), (0, 1), (0, 0)), mode='constant')\n",
    "\n",
    "\n",
    "np.info(input_day_padded)\n",
    "# Use the encoder to generate the encoded representation of this input day’s data\n",
    "#input_day_encoded = encoder.predict(input_day_padded)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1edf1672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class:  ndarray\n",
      "shape:  (1, 2, 41, 51, 128)\n",
      "strides:  (2141184, 1070592, 26112, 512, 4)\n",
      "itemsize:  4\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  False\n",
      "data pointer: 0x559299ab2b00\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: float32\n"
     ]
    }
   ],
   "source": [
    "encoded_input = encoder.predict(input_day_padded)\n",
    "np.info(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7adca43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class:  ndarray\n",
      "shape:  (511, 2, 41, 51, 128)\n",
      "strides:  (2141184, 1070592, 26112, 512, 4)\n",
      "itemsize:  4\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  False\n",
      "data pointer: 0x7f14b5914010\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: float32\n"
     ]
    }
   ],
   "source": [
    "np.info(encoded_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa898a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7be49079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[279 353 134 260 213 364 259  49 144  36 316 436 386 256 484  64 324 485\n",
      "  117  70 347 314 261 321 339 344  80 257 145 174 215 103 479 295  32 421\n",
      "  500 307 435 371 182 473 169 401 207  89 322 411 271 202 426  11 404 220\n",
      "   23 372 291 123 350 342 133 150 507  71 413  12  57  25 282   3  13 227\n",
      "  108 250 408 196 329 480 264 204 194 390  14  31 265 300 376 381 365  16\n",
      "  494  83  63 161 331 358  19 410  94 106 368  42 445 385 305  88 244 243\n",
      "  333 447 453 425 226 354  22  54 170  52 172 304 299 140 375  96 131  29\n",
      "   21 486 326 200 289 287 387   7 185 187 440 126 232 469 120 346  82 269\n",
      "  429 430 301 276 181 285 160 463 437   4 356 352 280 392  46  59 306 224\n",
      "  203 398  72  76 100 195  34  81 217 116 497  77 107 290 422 158 428 441\n",
      "  155 395 366 137 190 457 193 313 135 503 238 149  87 216  85  84 468  24\n",
      "  396 247 275 465  97 219 416 317 433 253 508 389  98 510 303 471  35  38\n",
      "   95  45 148  51 470 492 328 237 233 309 179 167 405 113 363 434 504 493\n",
      "  432 296 175 343  37 377  17 241 268 130 112 420   5 370 258 418 142 270\n",
      "  394 209 104 180 319 455  33 382 178  48 438 165 242 206  39  15 327 451\n",
      "  481   0 402 101 294 274 311 252 475 128 431 399  58 318  73 186 509 231\n",
      "  262 249 308 458 129  68 201 349 266 293 454  79 374 506 335 228  65 367\n",
      "   41 348 235 263  55 125 427 407 297 491  40  75 210 236 360  44  27  60\n",
      "  273   6 163 162 234  20 286 462 460 337 351 456 501 143 159 171 330 490\n",
      "  302 214 362  53 251 229 378 283 248 292  47  28 403 114 222 361 183 400\n",
      "   43 139 212 157 406 105 467  93   9  69 168 415 211 156 102 495 177  74\n",
      "  127 111 281 442 141 388 483 147 197  50  56 334 184 419  91 478 255 152\n",
      "  417 278 136 173 124 122 464 115  10 119 466 423 424 412 277 205   1 166\n",
      "  477 246 340 450 110 489 191 393 218 189 240 498 164 359 383 369 245  67\n",
      "   92 153 239 380 138  90 146  26  61  78 499 502 355 439  66 310 298 118\n",
      "  332 384 373 357 474 488 154 176 225 192 459  30 448 199 505 323 379 446\n",
      "  198 444 288 284 109 338 312   8  18 325 443 315 320 345 461 221 341   2\n",
      "  121 132 449 476 151 487 267 272 336 391 496 472 482 414 208 230  86 254\n",
      "  223 397  99 452  62 409 188]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate similarities and find the most similar day:\n",
    "\n",
    "# Use <Euclidean distances> to calculate the Euclidean distances between the input day's encoded representation and the encoded representations of all the days in the database.\n",
    "\n",
    "\n",
    "\n",
    "input_flattened = encoded_input.reshape(1,-1)\n",
    "database_flattened = encoded_database.reshape(encoded_database.shape[0], -1)\n",
    "\n",
    "\n",
    "#np.info(input_flattened)\n",
    "#np.info(database_flattened)\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Calculate Euclidean distances \n",
    "distances = euclidean_distances(input_flattened, database_flattened)\n",
    "\n",
    "indices_of_smallest = np.argsort(distances)[:3]\n",
    "\n",
    "print(indices_of_smallest)\n",
    "# Calculate Euclidean distances \n",
    "#distances = np.array([euclidean(input_flattened,sample) for sample in database_flattened])\n",
    "\n",
    "#indices_of_smallest = np.argsort(distance)[:3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a0cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Dimensionality Reduction on Encoded Representations (Optional)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming `encoded_data` contains encoded representations of your entire dataset\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(encoded_database.reshape(len(encoded_database), -1))\n",
    "\n",
    "sns.scatterplot(x=tsne_results[:,0], y=tsne_results[:,1], alpha=0.5)\n",
    "plt.title('t-SNE of Encoded Representations')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3 (default, Jul  2 2020, 16:21:59) \n[GCC 7.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "251620423460f143637fd62816989280992a1c1ba8078ecf2edc31a98a8a14b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
