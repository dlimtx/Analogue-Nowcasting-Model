{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a84d4c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, Add\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "\n",
    "# tf.config.list_physical_devices()\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7575599f-0931-4e09-b064-768ba5c1fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for both years\n",
    "data = nc.Dataset('ERA5_Data/ERA5_21_to_22_data_small.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7118e35-c2a3-4a14-a6a4-5df46c1a46b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.moveaxis(data['u'], 1, 0)\n",
    "v = np.moveaxis(data['v'], 1, 0)\n",
    "\n",
    "# z = np.concatenate((data_2020['z'][:], data_2021['z'][:]), axis=0)\n",
    "# u = np.concatenate((data_2020['u'][:], data_2021['u'][:]), axis=0)\n",
    "# v = np.concatenate((data_2020['v'][:], data_2021['v'][:]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d33199d9-baf2-4e35-9a46-86af7722edd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(730, 13, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11af605f-bf67-4996-abf6-e5f8afa3c193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "u_925 = scaler.fit_transform(u[2].reshape(-1, 1)).reshape(u[2].shape)\n",
    "v_925 = scaler.fit_transform(v[2].reshape(-1, 1)).reshape(v[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c47731-3566-40de-a133-93584f38924d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(730, 13, 17)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_925.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8916a9dd-9e56-40c8-9d0e-b889c9aecdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the data to get even dimensions\n",
    "u_925 = np.pad(u_925, ((0, 0), (0, 1), (0, 1)), mode='constant')\n",
    "v_925 = np.pad(v_925, ((0, 0), (0, 1), (0, 1)), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b0ab425-c752-4a56-a135-3739c36646e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(730, 14, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_925.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7979dd6b-7d1a-42f8-889d-fcae400789fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the parameters to form a single dataset\n",
    "data_combined = np.stack((u_925, v_925), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "185aefc0-2371-4587-ad49-8435487d2533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(730, 14, 18, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "253414cb-6d80-4815-bacc-6d61e04024ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_padded, X_val_padded = train_test_split(data_combined, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6ff5a11-016e-4e03-ae41-d721f6446e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511, 14, 18, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4e77603-ec91-41a9-9366-f0b84fbd45f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ResNet block\n",
    "def resnet_block(input_tensor, filters, kernel_size=(3, 3), strides=(1, 1)):\n",
    "    x = Conv2D(filters, kernel_size, strides=strides, padding='same')(input_tensor)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Adjust the shortcut connection\n",
    "    if strides != (1, 1) or input_tensor.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, (1, 1), strides=strides, padding='same')(input_tensor)\n",
    "    else:\n",
    "        shortcut = input_tensor\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1792d43-bea4-4ecb-baf8-53da2f64e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to constrain the input to the model\n",
    "# X_train_padded = np.split(X_train_padded, 5, axis=0)\n",
    "# print(len(X_train_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47f6b993-2ac4-4c63-ae1c-3ba8aaf2fdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 18, 2)\n"
     ]
    }
   ],
   "source": [
    "# Input requires us to provide the shape which is the H X W X C without the number of samples N.\n",
    "print(X_train_padded[0].shape)\n",
    "input = Input(shape=X_train_padded[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe31fdf5-f906-41ad-9ac8-aed4ab313c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "x = resnet_block(input, 32)\n",
    "x = resnet_block(x, 64)\n",
    "x = resnet_block(x, 128)\n",
    "x = resnet_block(x, 256)\n",
    "encoded = resnet_block(x, 256, strides=(2, 2))\n",
    "\n",
    "# Decoder\n",
    "x = UpSampling2D((2, 2))(encoded)\n",
    "x = resnet_block(x, 256)\n",
    "x = UpSampling2D((2, 2))(encoded)\n",
    "x = resnet_block(x, 128)\n",
    "x = UpSampling2D((2, 2))(encoded)\n",
    "x = resnet_block(x, 64)\n",
    "x = UpSampling2D((1, 1))(x)\n",
    "x = resnet_block(x, 32)\n",
    "decoded = Conv2D(2, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder = Model(input, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c12f3f6-83ff-4627-83b3-412c1287fad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 14, 18, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 14, 18, 32)   608         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 14, 18, 32)  128         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 14, 18, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 14, 18, 32)   9248        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 14, 18, 32)  128         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 14, 18, 32)   96          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 14, 18, 32)   0           ['batch_normalization_1[0][0]',  \n",
      "                                                                  'conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 14, 18, 32)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 14, 18, 64)   18496       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 14, 18, 64)  256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 14, 18, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 14, 18, 64)   36928       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 14, 18, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 14, 18, 64)   2112        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 14, 18, 64)   0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 14, 18, 64)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 14, 18, 128)  73856       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 14, 18, 128)  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 14, 18, 128)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 14, 18, 128)  147584      ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 14, 18, 128)  512        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 14, 18, 128)  8320        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 14, 18, 128)  0           ['batch_normalization_5[0][0]',  \n",
      "                                                                  'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 14, 18, 128)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 14, 18, 256)  295168      ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 18, 256)  1024       ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 14, 18, 256)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 14, 18, 256)  590080      ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 14, 18, 256)  1024       ['conv2d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 14, 18, 256)  33024       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 14, 18, 256)  0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 14, 18, 256)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 7, 9, 256)    590080      ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 7, 9, 256)   1024        ['conv2d_12[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 7, 9, 256)    0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 7, 9, 256)    590080      ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 7, 9, 256)   1024        ['conv2d_13[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 7, 9, 256)    65792       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 7, 9, 256)    0           ['batch_normalization_9[0][0]',  \n",
      "                                                                  'conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 7, 9, 256)    0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 14, 18, 256)  0          ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 14, 18, 64)   147520      ['up_sampling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 14, 18, 64)  256         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 14, 18, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 14, 18, 64)   36928       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 14, 18, 64)  256         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 14, 18, 64)   16448       ['up_sampling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 14, 18, 64)   0           ['batch_normalization_15[0][0]', \n",
      "                                                                  'conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 14, 18, 64)   0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 14, 18, 64)  0           ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 14, 18, 32)   18464       ['up_sampling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 14, 18, 32)  128         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 14, 18, 32)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 14, 18, 32)   9248        ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 14, 18, 32)  128         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 14, 18, 32)   2080        ['up_sampling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 14, 18, 32)   0           ['batch_normalization_17[0][0]', \n",
      "                                                                  'conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 14, 18, 32)   0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 14, 18, 2)    578         ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,699,394\n",
      "Trainable params: 2,696,066\n",
      "Non-trainable params: 3,328\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65be841e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 9s 190ms/step - loss: 0.0245 - accuracy: 0.7625 - val_loss: 0.0414 - val_accuracy: 0.6527\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0032 - accuracy: 0.8750 - val_loss: 0.0332 - val_accuracy: 0.6526\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0022 - accuracy: 0.8961 - val_loss: 0.0321 - val_accuracy: 0.6714\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0019 - accuracy: 0.8931 - val_loss: 0.0304 - val_accuracy: 0.6867\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0021 - accuracy: 0.8844 - val_loss: 0.0323 - val_accuracy: 0.6696\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0017 - accuracy: 0.8872 - val_loss: 0.0343 - val_accuracy: 0.7020\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0015 - accuracy: 0.8828 - val_loss: 0.0330 - val_accuracy: 0.6502\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0013 - accuracy: 0.8953 - val_loss: 0.0311 - val_accuracy: 0.6731\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0019 - accuracy: 0.9008 - val_loss: 0.0278 - val_accuracy: 0.6862\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0015 - accuracy: 0.8949 - val_loss: 0.0281 - val_accuracy: 0.7134\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0019 - accuracy: 0.8758 - val_loss: 0.0268 - val_accuracy: 0.7016\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0014 - accuracy: 0.8965 - val_loss: 0.0284 - val_accuracy: 0.6839\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0018 - accuracy: 0.8690 - val_loss: 0.0281 - val_accuracy: 0.6963\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0014 - accuracy: 0.9024 - val_loss: 0.0262 - val_accuracy: 0.7186\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0010 - accuracy: 0.8984 - val_loss: 0.0248 - val_accuracy: 0.7247\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 9.3082e-04 - accuracy: 0.8993 - val_loss: 0.0246 - val_accuracy: 0.7247\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 9.0179e-04 - accuracy: 0.8976 - val_loss: 0.0244 - val_accuracy: 0.7342\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0011 - accuracy: 0.8953 - val_loss: 0.0242 - val_accuracy: 0.7157\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0012 - accuracy: 0.8871 - val_loss: 0.0228 - val_accuracy: 0.7582\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0010 - accuracy: 0.8939 - val_loss: 0.0212 - val_accuracy: 0.7843\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "history = autoencoder.fit(X_train_padded, X_train_padded, epochs=20, batch_size=32, validation_data=(X_val_padded, X_val_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6c4e70c-8adb-4b80-8a3c-af57c28aa9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to constrain the input to the model\n",
    "# for i in range(1,5):\n",
    "#     history = autoencoder.fit(X_train_padded[i], X_train_padded[i], epochs=20, batch_size=16, validation_data=(X_val_padded, X_val_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea5d876e-c3dd-483f-9852-b0442dd402df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss per iteration\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# For increasing validation loss, it is a sign we are overfitting and can be reduced by normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b94129-b9f9-42c4-98cd-4cf307136283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this model\n",
    "autoencoder.save('Saved Models/ResNet_00Z_925_Autoencoder.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3728d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "autoencoder.save_weights('Saved Models/ResNet_00Z_925_Autoencoder_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146c5b58-b724-420d-a31b-c2a952ca7669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "autoencoder = load_model('Saved Models/ResNet_00Z_925_Autoencoder.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d63020-9918-4599-8636-7c153aed7924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "autoencoder.compile(optimizer='adam', loss='mse',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2034a2a8-8343-436a-9a89-9b14304bf588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder model. Find the low dimension layer according to the model summary. 'activation_15' should be the encoder layer\n",
    "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('activation_9').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb76ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the history object \n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Convert the history.history dict to a pandas DataFrame\n",
    "hist_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Save to csv\n",
    "hist_csv_file = 'Saved Models/history_925.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)\n",
    "\n",
    "# Save to pickle\n",
    "with open('Saved Models/history_925.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e97057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved history \n",
    "loaded_history = pd.read_csv('Saved Models/history_925.csv')\n",
    "\n",
    "with open('Saved Models/history_925.pkl', 'rb') as file:\n",
    "    loaded_history = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51311e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate Encoded Representations for the Database\n",
    "encoded_database = encoder.predict(data_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "416a39c5-1379-44ce-8743-c40d9cb25326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(730, 7, 9, 256)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_database.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c48e1b4-70c5-4884-b30c-8ec94863532a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1, 13, 17)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Provide a test image for similarity check\n",
    "# Load the data for input say\n",
    "input_data = nc.Dataset('ERA5_Data/ERA5_28Nov23Input.nc')\n",
    "\n",
    "# Extract data\n",
    "u_input = np.moveaxis(input_data['u'], 1, 0)\n",
    "v_input = np.moveaxis(input_data['v'], 1, 0)\n",
    "\n",
    "u_input.shape\n",
    "# Input data [0][0] is 700hPa, [0][1] is 850hPa and [0][2] is 925hPa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21e4d0e5-36aa-489c-b7be-b215df4bd0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 13, 17)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data['u'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c42b8d35-fc62-4150-ac48-1ddea38a882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "u_input = scaler.fit_transform(u_input[2].reshape(-1, 1)).reshape(u_input[2].shape)\n",
    "v_input = scaler.fit_transform(v_input[2].reshape(-1, 1)).reshape(v_input[2].shape)\n",
    "\n",
    "# Pad the data to get even dimensions\n",
    "u_input = np.pad(u_input, ((0, 0), (0, 1), (0, 1)), mode='constant')\n",
    "v_input = np.pad(v_input, ((0, 0), (0, 1), (0, 1)), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87be871f-72a6-46d1-bd75-c1470e0db68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 14, 18)\n"
     ]
    }
   ],
   "source": [
    "print(u_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5059d2f-1ca5-4671-abac-fcdf329d0589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the parameters to form a single dataset\n",
    "input_data_combined = np.stack((u_input, v_input), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6e33465-7bc5-4b41-981f-66f55fce605b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 14, 18, 2) (730, 14, 18, 2)\n"
     ]
    }
   ],
   "source": [
    "# Make sure shapes match between input_data and database data\n",
    "print(input_data_combined.shape,data_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "380596de-9f59-4b4d-aff6-4c4ded1d5eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 13\n",
      "17 13\n"
     ]
    }
   ],
   "source": [
    "# Visualize test image\n",
    "# x, y = np.meshgrid(np.linspace(95, 120, 101), np.linspace(-5, 15, 81))\n",
    "x = np.linspace(102, 106, 17)\n",
    "y = np.linspace(3, 0, 13)\n",
    "\n",
    "# Check lengths are consistent\n",
    "print(len(x),len(y))\n",
    "print(len(input_data['z'][0][2][0]), len(input_data['z'][0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc9972aa-4aba-4e8e-9f18-f0d0e3f6af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_rgb(angle, absolute):\n",
    "    global max_abs\n",
    "\n",
    "    # normalize angle\n",
    "    angle = angle % (2 * np.pi)\n",
    "    if angle < 0:\n",
    "        angle += 2 * np.pi\n",
    "\n",
    "    return matplotlib.colors.hsv_to_rgb((angle / 2 / np.pi, \n",
    "                                         absolute / max_abs, \n",
    "                                         absolute / max_abs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72f079cb-cc3c-475a-b519-25ef25aa49ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: qt. Using qt5 instead.\n"
     ]
    }
   ],
   "source": [
    "# Visualize test image\n",
    "# Plot 925 winds\n",
    "# plt.quiver(x, y, input_data['u'][0][2], input_data['v'][0][2], scale_units='xy')\n",
    "\n",
    "# plt.quiver(x, y, input_data['u'][0][2], input_data['v'][0][2], np.arctan2(input_data['v'][0][2], input_data['u'][0][2]),\n",
    "#            angles='xy',\n",
    "#            scale_units='xy', \n",
    "#            pivot='mid',\n",
    "#            color='g'\n",
    "#           )\n",
    "\n",
    "\n",
    "X = x\n",
    "Y = y\n",
    "U = input_data['u'][0][2]\n",
    "V = input_data['v'][0][2]\n",
    "\n",
    "angles = np.arctan2(input_data['v'][0][2], input_data['u'][0][2])\n",
    "lengths = np.sqrt(np.square(input_data['u'][0][2]) + np.square(input_data['v'][0][2]))\n",
    "\n",
    "angles = np.arctan2(V, U)\n",
    "lengths = np.sqrt(np.square(U) + np.square(V))\n",
    "\n",
    "max_abs = np.max(lengths)\n",
    "c = np.array(list(map(vector_to_rgb, angles.flatten(), lengths.flatten())))\n",
    "\n",
    "%matplotlib qt\n",
    "plt.quiver(X, Y, U, V, color=c)\n",
    "plt.title('28 Nov 2023 925 winds')\n",
    "plt.show()\n",
    "\n",
    "# Visualisation looks correct compared iwht EC Deterministic image on Optic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd092414-dbf4-44b9-9442-b87b7d223f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 297ms/step\n"
     ]
    }
   ],
   "source": [
    "input_day_encoded = encoder.predict(input_data_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1670449a-66a6-495d-b6a3-e72b20e96b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image encoded shape (1, 7, 9, 256)\n",
      "Encoded database shape (730, 7, 9, 256)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input image encoded shape\", input_day_encoded.shape)\n",
    "print(\"Encoded database shape\", encoded_database.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbe91a0d-82b1-48b5-88a0-2216daf421af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image encoded flat shape: (1, 16128)\n",
      "Encoded flat shape: (730, 16128)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping to allow calculating of euclidean distances\n",
    "input_day_encoded_flat = input_day_encoded.reshape(1,-1)\n",
    "encoded_database_flat = encoded_database.reshape(encoded_database.shape[0], -1)\n",
    "\n",
    "print(\"Input image encoded flat shape:\", input_day_encoded_flat.shape)\n",
    "print(\"Encoded flat shape:\", encoded_database_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06d1add9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n",
      "[0.19937384 0.5899825  0.5648222  ... 0.         0.         0.36583006]\n"
     ]
    }
   ],
   "source": [
    "# Calculate similarities and find the most similar day:\n",
    "# Use <Euclidean distances> to calculate the Euclidean distances between the input day's encoded representation and the encoded representations of all the days in the database.\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Calculate Euclidean distances \n",
    "distances = euclidean_distances(input_day_encoded_flat, encoded_database_flat)\n",
    "\n",
    "# Find the index of the most similar day (smallest distance)\n",
    "most_similar_day_index = np.argmin(distances)\n",
    "\n",
    "# Retrieve the data of the most similar day\n",
    "most_similar_day_data = encoded_database_flat[most_similar_day_index]\n",
    "\n",
    "print(most_similar_day_index)\n",
    "print(most_similar_day_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2576e70f-ea33-4d77-91ac-df46cdd9206e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: qt. Using qt5 instead.\n"
     ]
    }
   ],
   "source": [
    "# Visualise most similar database image\n",
    "X = x\n",
    "Y = y\n",
    "U = data['u'][most_similar_day_index][2]\n",
    "V = data['v'][most_similar_day_index][2]\n",
    "\n",
    "angles = np.arctan2(V, U)\n",
    "lengths = np.sqrt(np.square(U) + np.square(V))\n",
    "\n",
    "max_abs = np.max(lengths)\n",
    "c = np.array(list(map(vector_to_rgb, angles.flatten(), lengths.flatten())))\n",
    "\n",
    "%matplotlib qt\n",
    "plt.quiver(X, Y, U, V, color=c)\n",
    "plt.title('Most similar day 925 winds')\n",
    "plt.savefig(\"Visualisation/925_only_most_similar_wings.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "251620423460f143637fd62816989280992a1c1ba8078ecf2edc31a98a8a14b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
